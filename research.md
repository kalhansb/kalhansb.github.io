---
layout: page
title: Research
permalink: /research/
---

## Current Research Projects

### Cooperative Perception in Robotic Teams for Sustainable Environments
**PhD Project** | Nottingham Trent University | Oct 2023 - Present

My doctoral research investigates active perception strategies to improve the efficiency of multi-robot teams in dynamic outdoor environments. Rather than treating perception as passive sensing, I explore how robots can dynamically decide *what*, *when*, and *where* to perceive to maximize information gain and task performance.

**Key Focus Areas:**
- Active sensor management in multi-robot systems
- Cooperative information gathering under communication constraints
- Outdoor robotics applications for sustainable practices
- High-fidelity simulation using ROS 2 and Gazebo

---

## Active Projects

### OHMS-NetSim: Multi-Robot Physics-Network Co-Simulator
**Repository:** [github.com/RAISE-NTU/ohms_netsim](https://github.com/RAISE-NTU/ohms_netsim)

A high-fidelity simulation framework for multi-robot teams that co-simulates both physical dynamics and realistic network communication.

**Key Contributions:**
- Custom C++ Gazebo plugins for obstacle-dependent communication modeling
- Integration of ROS 2 Humble with Gazebo Fortress
- Realistic multi-robot outdoor environment simulation
- Network-aware coordination algorithm validation

**Technologies:** C++, Python, ROS 2, Gazebo, Network Simulation

**Publication:** *OHMS-NetSim: Enabling Obstacle-Aware Network-Physics Co-Simulation for Outdoor Multi-Robot Applications*, UKCI 2025 (Forthcoming)

### Jetbot VLM Navigator
**Repository:** [github.com/kalhansb/jetbot_vlm_navigator](https://github.com/kalhansb/jetbot_vlm_navigator)

A Vision-Language Model (VLM)-driven navigation system for the NVIDIA Jetbot platform. This project explores semantic scene understanding using multimodal AI models.

**Key Contributions:**
- VLM integration for semantic navigation
- RGB camera-based decision-making
- Robust control interface with safety mechanisms
- Real-time processing on edge devices (Jetson Nano)

**Technologies:** Python, ROS 2, Vision-Language Models, NVIDIA Jetson

---

## Research Themes

### Active Cooperative Perception
Developing algorithms that enable multi-robot teams to actively decide *what*, *when*, and *where* to sense so as to maximise information gain and improve task performance — particularly for outdoor and dynamic environments. This includes active sensor management, decision-theoretic information measures, and simulation-to-reality validation.

### Network-Aware Coordination
Investigating coordination methods that adapt to communication constraints and realistic degradation (e.g., obstacle-dependent loss). This covers network-aware planning, communication-efficient information sharing, and co-simulation of physics and networks to evaluate algorithms under realistic conditions.

### Additional Themes
- Sustainable Robotics: Applications in environmental monitoring, precision agriculture, and forestry  
- Simulation to Reality: High-fidelity simulation frameworks (ROS 2, Gazebo) and hardware validation

---

## Publications

### Book Chapters

**Cooperative Perception in Outdoor Robotics for a Sustainable Environment**  
Book chapter in *Recent Advances in Robotic Perception for Forestry*  
*Forthcoming*


### Journal Articles

**Cooperative Perception for Multi-Robot Systems in Natural Outdoor Applications — A Survey**  
*Journal of Intelligent & Robotic Systems*  
*Under Review*


### Conference Papers

**OHMS-NetSim: Enabling Obstacle-Aware Network-Physics Co-Simulation for Outdoor Multi-Robot Applications**  
*UK Workshop on Computational Intelligence (UKCI)*, 2025  
*Forthcoming*

**Solar Photovoltaic Energy Forecasting Using Improved Ensemble Method For Micro-grid Energy Management**  
*IEEE International Conference on Intelligent Systems for Science and Society (iSSSC)*, 2022  

**Non-Intrusive Load Monitoring Using Denoising Autoencoder Neural Networks**  
*IEEE Region 10 Humanitarian Technology Conference (R10-HTC)*, 2022  

**Exploring Embodied Resources in Gaze in Human-Robot Collaborative Environments**  
*Embodied Intelligence Conference*, 2022  

[Google Scholar Profile](https://scholar.google.com/citations?hl=en&user=6-OKLyIAAAAJ&view_op=list_works&sortby=pubdate)

---

## Technical Skills

**Core Robotics:** ROS 2, Nav2, Multi-Robot Communication, Active Perception, 3D Mapping

**Simulation & AI:** Gazebo, Unity 3D for Digital Twins, Machine Learning, Reinforcement Learning, Deep Learning

**Hardware:** Jetbot, Realsense RGB-D Cameras

**Programming:** Python, C++, MATLAB, Git, Linux/Bash, LaTeX

---

## Previous Research Experience

### Research Associate | Nottingham Trent University | Mar 2023 - Sep 2023
Developed a high-fidelity digital twin using Unity 3D to simulate a smart home sensor system. Implemented machine learning techniques to classify human action within the virtual environment.

### Research Assistant | University of Moratuwa | Jun 2021 - Jun 2022
Contributed to research on energy management systems and multi-agent control strategies.

### Research Assistant | University of Moratuwa | Jul 2018 - Dec 2020
Worked on various projects in energy systems and machine learning applications.

